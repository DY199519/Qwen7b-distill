import json
import argparse
import sys
from typing import List, Dict, Any, Union, Set, Tuple
from pathlib import Path
from datetime import datetime

# ==============================================
# ğŸ“ modify the folder path
# ==============================================

# basic directory configuration
BASE_DIR = Path(r"D:\project7\prompt")
BASE_DIR_1 = Path(r"D:\project7")
BASE_DIR_2 = Path(r"D:\project7\merge10000")

# merge the JSON files
files_to_merge = [
    BASE_DIR_2 / "grades-3+1-1-3600.json",      
    BASE_DIR_2 / "grades-3+1-3600-4400.json",       
    BASE_DIR_2 / "grades-3+1-4400-5000.json",       
    BASE_DIR_2 / "grades-3+1-5000-5800.json",      
    BASE_DIR_2 / "grades-3+1-5800-6300.json",      
    BASE_DIR_2 / "grades-3+1-6300-6800.json",    
    BASE_DIR_2 / "grades-3+1-6800-7800.json",       
    BASE_DIR_2 / "grades-3+1-7800-8100.json",       
    BASE_DIR_2 / "grades-3+1-8100-8600.json",       
    BASE_DIR_2 / "grades-3+1-8600-8900.json",      
    BASE_DIR_2 / "grades-3+1-8900-9400.json",       

]
# output file path
output_file = BASE_DIR_2 / "grades-3+1-1-9400.json"

# aotumatically generate
incomplete_output_file = BASE_DIR_2 / "incomplete_questions1-3600.json"

# ==============================================
# âš™ï¸ modify function options
# ==============================================

preview_only = False

rename_default_fields_flag = True

# Whether to check the integrity of the model answers (only valid for files of the multi_model_answer type)
check_model_completeness = True

# Required model list (using fuzzy matching)
required_models = ["doubao-pro", "gemini-2.5-flash", "grok-3"]

# Whether to save incomplete questions separately
save_incomplete_separately = True


def load_json_files(file_paths: List[str]) -> List[Dict]:
    """
        loading multiply JSON
    
    Args:
        file_paths: 
        
    Returns:
        List of loaded JSON data
    """
    json_data = []
    
    for file_path in file_paths:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                json_data.append(data)
                print(f"successfully load: {file_path}")
        except FileNotFoundError:
            print(f"ERROR: The file {file_path} does not exist.")
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"ERROR: The file {file_path} is not valid JSON: {e}")
            sys.exit(1)
        except Exception as e:
            print(f"ERROR: An error occurred while reading the file {file_path}: {e}")
            sys.exit(1)
    
    return json_data


def detect_merge_type(json_data: List[Dict]) -> str:
    """
    Detect merge type
    
    Args:
        json_data: 
        
    Returns:
        'list' 
        'detailed_results' 
        'questions' 
        'grade'
    """
    if not json_data:
        return 'unknown'
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ•°æ®çš„ç±»å‹
    first_data = json_data[0]
    
    # æƒ…å†µ1: æ•°æ®æ˜¯å­—å…¸åˆ—è¡¨ [{dict1, dict2}, {dict3, dict4}]
    if isinstance(first_data, list) and all(isinstance(item, dict) for item in first_data):
        # éªŒè¯æ‰€æœ‰æ•°æ®éƒ½æ˜¯å­—å…¸åˆ—è¡¨
        if all(isinstance(data, list) and all(isinstance(item, dict) for item in data) for data in json_data):
            return 'list'
    
    # æƒ…å†µ2: æ•°æ®æ˜¯åŒ…å«statisticså’Œdetailed_resultsçš„è¯„åˆ†æ–‡ä»¶
    elif isinstance(first_data, dict) and 'statistics' in first_data and 'detailed_results' in first_data:
        # éªŒè¯æ‰€æœ‰æ•°æ®éƒ½åŒ…å«è¿™ä¸¤ä¸ªå­—æ®µ
        if all(isinstance(data, dict) and 'statistics' in data and 'detailed_results' in data for data in json_data):
            return 'grade'
    
    # æƒ…å†µ3: æ•°æ®æ˜¯åŒ…å«detailed_resultså­—æ®µçš„å­—å…¸ï¼ˆä½†ä¸æ˜¯gradeæ–‡ä»¶ï¼‰
    elif isinstance(first_data, dict) and 'detailed_results' in first_data:
        # éªŒè¯æ‰€æœ‰æ•°æ®éƒ½åŒ…å«detailed_resultså­—æ®µ
        if all(isinstance(data, dict) and 'detailed_results' in data for data in json_data):
            return 'detailed_results'
    
    # æƒ…å†µ4: æ•°æ®æ˜¯åŒ…å«questionså­—æ®µçš„å­—å…¸
    elif isinstance(first_data, dict) and 'questions' in first_data:
        # éªŒè¯æ‰€æœ‰æ•°æ®éƒ½åŒ…å«questionså­—æ®µ
        if all(isinstance(data, dict) and 'questions' in data for data in json_data):
            return 'questions'
    
    return 'unknown'


def fuzzy_match_model(model_name: str, required_models: List[str]) -> bool:
    """
    ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åŒ¹é…å¿…éœ€çš„æ¨¡å‹
    
    Args:
        model_name: è¦æ£€æŸ¥çš„æ¨¡å‹åç§°
        required_models: å¿…éœ€çš„æ¨¡å‹åˆ—è¡¨
        
    Returns:
        æ˜¯å¦åŒ¹é…
    """
    model_name_lower = model_name.lower().strip()
    
    for required_model in required_models:
        required_model_lower = required_model.lower().strip()
        
        # æ£€æŸ¥å„ç§å¯èƒ½çš„åŒ¹é…æƒ…å†µ
        if (required_model_lower in model_name_lower or 
            model_name_lower in required_model_lower or
            required_model_lower.replace('-', '') in model_name_lower.replace('-', '') or
            model_name_lower.replace('-', '') in required_model_lower.replace('-', '')):
            return True
    
    return False


def check_model_answers(questions_dict: Dict[str, Dict], required_models: List[str]) -> Tuple[bool, List[Dict], Dict[str, Dict]]:
    """
    æ£€æŸ¥æ¯ä¸ªé—®é¢˜æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹ç­”æ¡ˆï¼ˆä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼‰
    
    Args:
        questions_dict: é—®é¢˜å­—å…¸
        required_models: å¿…éœ€çš„æ¨¡å‹åˆ—è¡¨
        
    Returns:
        (æ˜¯å¦æ‰€æœ‰é—®é¢˜éƒ½ç¬¦åˆè¦æ±‚, ç¼ºå¤±ä¿¡æ¯åˆ—è¡¨, ä¸å®Œæ•´çš„é—®é¢˜å­—å…¸)
    """
    missing_info = []
    incomplete_questions = {}
    all_valid = True
    
    for question, question_data in questions_dict.items():
        if 'answers' not in question_data:
            missing_info.append({
                'question': question,
                'issue': 'ç¼ºå°‘answerså­—æ®µ',
                'missing_models': required_models
            })
            all_valid = False
            incomplete_questions[question] = question_data.copy()
            continue
        
        existing_models = list(question_data['answers'].keys())
        
        # æ£€æŸ¥æ¯ä¸ªå¿…éœ€çš„æ¨¡å‹æ˜¯å¦æœ‰åŒ¹é…
        missing_models = []
        for required_model in required_models:
            found = False
            for existing_model in existing_models:
                if fuzzy_match_model(existing_model, [required_model]):
                    found = True
                    break
            if not found:
                missing_models.append(required_model)
        
        if missing_models:
            missing_info.append({
                'question': question,
                'issue': 'ç¼ºå°‘éƒ¨åˆ†æ¨¡å‹ç­”æ¡ˆ',
                'missing_models': missing_models,
                'existing_models': existing_models
            })
            all_valid = False
            incomplete_questions[question] = question_data.copy()
    
    return all_valid, missing_info, incomplete_questions


def separate_complete_incomplete_questions(questions_dict: Dict[str, Dict], required_models: List[str]) -> Tuple[Dict[str, Dict], Dict[str, Dict]]:
    """
    å°†é—®é¢˜åˆ†ä¸ºå®Œæ•´å’Œä¸å®Œæ•´ä¸¤éƒ¨åˆ†ï¼ˆä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ï¼‰
    
    Args:
        questions_dict: åŸå§‹é—®é¢˜å­—å…¸
        required_models: å¿…éœ€çš„æ¨¡å‹åˆ—è¡¨
        
    Returns:
        (å®Œæ•´çš„é—®é¢˜å­—å…¸, ä¸å®Œæ•´çš„é—®é¢˜å­—å…¸)
    """
    complete_questions = {}
    incomplete_questions = {}
    
    for question, question_data in questions_dict.items():
        if 'answers' not in question_data:
            incomplete_questions[question] = question_data.copy()
            continue
        
        existing_models = list(question_data['answers'].keys())
        
        # æ£€æŸ¥æ¯ä¸ªå¿…éœ€çš„æ¨¡å‹æ˜¯å¦æœ‰åŒ¹é…
        missing_models = []
        for required_model in required_models:
            found = False
            for existing_model in existing_models:
                if fuzzy_match_model(existing_model, [required_model]):
                    found = True
                    break
            if not found:
                missing_models.append(required_model)
        
        if missing_models:
            incomplete_questions[question] = question_data.copy()
        else:
            complete_questions[question] = question_data.copy()
    
    return complete_questions, incomplete_questions


def merge_dict_lists(json_data: List[List[Dict]]) -> List[Dict]:
    """
    åˆå¹¶å­—å…¸åˆ—è¡¨
    
    Args:
        json_data: å­—å…¸åˆ—è¡¨çš„åˆ—è¡¨
        
    Returns:
        åˆå¹¶åçš„å­—å…¸åˆ—è¡¨
    """
    merged_list = []
    
    for data_list in json_data:
        merged_list.extend(data_list)
    
    return merged_list


def calculate_score_distribution(detailed_results: List[Dict]) -> Dict[str, int]:
    """
    è®¡ç®—åˆ†æ•°åˆ†å¸ƒ
    
    Args:
        detailed_results: è¯¦ç»†ç»“æœåˆ—è¡¨
        
    Returns:
        åˆ†æ•°åˆ†å¸ƒå­—å…¸
    """
    distribution = {
        "0-20": 0,
        "20-30": 0,
        "30-40": 0,
        "40-50": 0
    }
    
    for result in detailed_results:
        if 'avg_score_100' in result:
            score = result['avg_score_100']
        elif 'avg_scores' in result and 'total' in result['avg_scores']:
            score = result['avg_scores']['total'] * 2  # è½¬æ¢ä¸º100åˆ†åˆ¶
        else:
            continue
            
        if score < 20:
            distribution["0-20"] += 1
        elif score < 30:
            distribution["20-30"] += 1
        elif score < 40:
            distribution["30-40"] += 1
        elif score <= 50:
            distribution["40-50"] += 1
    
    return distribution


def merge_grade_files(json_data: List[Dict]) -> Dict:
    """
    åˆå¹¶åŒ…å«statisticså’Œdetailed_resultsçš„è¯„åˆ†æ–‡ä»¶
    
    Args:
        json_data: åŒ…å«statisticså’Œdetailed_resultsçš„å­—å…¸åˆ—è¡¨
        
    Returns:
        åˆå¹¶åçš„å­—å…¸
    """
    if not json_data:
        return {}
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå­—å…¸ä½œä¸ºåŸºç¡€
    merged_dict = json_data[0].copy()
    merged_detailed_results = []
    
    # åˆå¹¶æ‰€æœ‰detailed_results
    for data in json_data:
        if 'detailed_results' in data and isinstance(data['detailed_results'], list):
            merged_detailed_results.extend(data['detailed_results'])
    
    # æ›´æ–°merged_dict
    merged_dict['detailed_results'] = merged_detailed_results
    
    # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if 'statistics' in merged_dict:
        stats = merged_dict['statistics']
        
        # é‡æ–°è®¡ç®—æ€»é—®é¢˜æ•°
        stats['total_questions'] = len(merged_detailed_results)
        
        # ç»Ÿè®¡æœ‰æ•ˆè¯„åˆ†
        valid_count = 0
        total_scores = []
        
        for result in merged_detailed_results:
            if 'avg_scores' in result and 'total' in result['avg_scores']:
                valid_count += 1
                total_scores.append(result['avg_scores']['total'])
        
        stats['valid_grades'] = valid_count
        stats['failed_grades'] = stats['total_questions'] - valid_count
        
        # é‡æ–°è®¡ç®—å¹³å‡åˆ†
        if total_scores:
            stats['total_average'] = sum(total_scores) / len(total_scores)
            stats['total_average_100'] = stats['total_average'] * 2
        
        # é‡æ–°è®¡ç®—åˆ†æ•°åˆ†å¸ƒ
        stats['score_distribution'] = calculate_score_distribution(merged_detailed_results)
        
        # æ›´æ–°å®Œæˆæ—¶é—´
        stats['completion_time'] = datetime.now().isoformat()
        
        # å¦‚æœæœ‰field_statisticsï¼Œä¹Ÿæ›´æ–°å®ƒ
        if 'field_statistics' in stats:
            for field_name in stats['field_statistics']:
                stats['field_statistics'][field_name]['count'] = valid_count
                if total_scores:
                    stats['field_statistics'][field_name]['average'] = stats['total_average']
                    stats['field_statistics'][field_name]['average_100'] = stats['total_average_100']
    
    return merged_dict


#def merge_detailed_results(json_data: List[Dict]) -> Dict:


def merge_questions(json_data: List[Dict]) -> Dict:
    """
    åˆå¹¶åŒ…å«questionså­—æ®µçš„å­—å…¸
    
    Args:
        json_data: åŒ…å«questionså­—æ®µçš„å­—å…¸åˆ—è¡¨
        
    Returns:
        åˆå¹¶åçš„å­—å…¸
    """
    if not json_data:
        return {}
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå­—å…¸ä½œä¸ºåŸºç¡€
    merged_dict = json_data[0].copy()
    merged_questions = merged_dict.get('questions', {}).copy()
    
    # åˆå¹¶æ‰€æœ‰questions
    for data in json_data[1:]:  # ä»ç¬¬äºŒä¸ªå¼€å§‹ï¼Œå› ä¸ºç¬¬ä¸€ä¸ªå·²ç»ä½œä¸ºåŸºç¡€
        if 'questions' in data and isinstance(data['questions'], dict):
            for question_key, question_data in data['questions'].items():
                if question_key in merged_questions:
                    # å¦‚æœé—®é¢˜å·²å­˜åœ¨ï¼Œéœ€è¦åˆå¹¶answers
                    if 'answers' in merged_questions[question_key] and 'answers' in question_data:
                        # åˆå¹¶answerså­—å…¸
                        merged_questions[question_key]['answers'].update(question_data['answers'])
                    # ä¿ç•™å…¶ä»–å­—æ®µï¼ˆå¦‚categoriesç­‰ï¼‰
                    for key, value in question_data.items():
                        if key != 'answers':
                            merged_questions[question_key][key] = value
                else:
                    # å¦‚æœé—®é¢˜ä¸å­˜åœ¨ï¼Œç›´æ¥æ·»åŠ 
                    merged_questions[question_key] = question_data.copy()
    
    # æ›´æ–°merged_dict
    merged_dict['questions'] = merged_questions
    
    return merged_dict


def rename_default_fields(data: Union[List[Dict], Dict]) -> Union[List[Dict], Dict]:
    """
    é‡å‘½ådefault_replyå’Œdefault_promptå­—æ®µä¸ºcombination_1æ ¼å¼
    
    Args:
        data: éœ€è¦å¤„ç†çš„æ•°æ®
        
    Returns:
        å¤„ç†åçš„æ•°æ®
    """
    if isinstance(data, list):
        return [rename_default_fields(item) for item in data]
    elif isinstance(data, dict):
        # å¤„ç†å­—å…¸
        processed_dict = {}
        
        # å¤„ç†å­—æ®µé‡å‘½å
        for key, value in data.items():
            if key == 'default_reply':
                new_key = "combination_1_reply"
                processed_dict[new_key] = value
            elif key == 'default_prompt':
                new_key = "combination_1_prompt"
                processed_dict[new_key] = value
            else:
                # é€’å½’å¤„ç†åµŒå¥—çš„å­—å…¸æˆ–åˆ—è¡¨
                processed_dict[key] = rename_default_fields(value)
        
        return processed_dict
    else:
        return data


def save_json(data: Union[List[Dict], Dict], output_path: str) -> None:
    """
    ä¿å­˜JSONæ•°æ®åˆ°æ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"åˆå¹¶ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"é”™è¯¯: ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


def save_incomplete_questions(incomplete_questions: Dict[str, Dict], incomplete_info: List[Dict], output_path: str) -> None:
    """
    ä¿å­˜ä¸å®Œæ•´çš„é—®é¢˜åˆ°å•ç‹¬çš„JSONæ–‡ä»¶
    
    Args:
        incomplete_questions: ä¸å®Œæ•´çš„é—®é¢˜å­—å…¸
        incomplete_info: ç¼ºå¤±ä¿¡æ¯åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # åˆ›å»ºåŒ…å«è¯¦ç»†ä¿¡æ¯çš„æ•°æ®ç»“æ„
    incomplete_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "total_incomplete_questions": len(incomplete_questions),
            "required_models": required_models,
            "source_files": [str(f) for f in files_to_merge]
        },
        "questions": incomplete_questions,
        "missing_info": incomplete_info
    }
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(incomplete_data, f, ensure_ascii=False, indent=2)
        print(f"ä¸å®Œæ•´çš„é—®é¢˜å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"é”™è¯¯: ä¿å­˜ä¸å®Œæ•´é—®é¢˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def main():
    # ==============================================
    # ä¸»ç¨‹åºé€»è¾‘
    # ==============================================
    
    # ä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    parser = argparse.ArgumentParser(description='åˆå¹¶å¤šä¸ªJSONæ–‡ä»¶')
    parser.add_argument('files', nargs='*', help='è¦åˆå¹¶çš„JSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–è„šæœ¬ä¸­çš„é…ç½®ï¼‰')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¼šè¦†ç›–è„šæœ¬ä¸­çš„é…ç½®ï¼‰')
    parser.add_argument('--preview', action='store_true', help='ä»…é¢„è§ˆåˆå¹¶ç»“æœï¼Œä¸ä¿å­˜æ–‡ä»¶')
    parser.add_argument('--rename-defaults', action='store_true', help='é‡å‘½ådefault_replyå’Œdefault_promptå­—æ®µä¸ºç¬¬ä¸€ä¸ªcombinationæ ¼å¼')
    parser.add_argument('--check-models', action='store_true', help='æ£€æŸ¥æ¯ä¸ªé—®é¢˜æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹ç­”æ¡ˆ')
    parser.add_argument('--no-check-models', action='store_true', help='è·³è¿‡æ¨¡å‹ç­”æ¡ˆå®Œæ•´æ€§æ£€æŸ¥')
    parser.add_argument('--incomplete-output', help='ä¸å®Œæ•´é—®é¢˜çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é»˜è®¤é…ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
    if args.files:
        global files_to_merge
        files_to_merge = args.files
    if args.output:
        global output_file
        output_file = args.output
    if args.preview:
        global preview_only
        preview_only = True
    if args.rename_defaults:
        global rename_default_fields_flag
        rename_default_fields_flag = True
    if args.check_models:
        global check_model_completeness
        check_model_completeness = True
    if args.no_check_models:
        check_model_completeness = False
    if args.incomplete_output:
        global incomplete_output_file
        incomplete_output_file = args.incomplete_output
    
    # æ£€æŸ¥æ–‡ä»¶æ•°é‡
    if len(files_to_merge) < 2:
        print("é”™è¯¯: è¯·æä¾›2-4ä¸ªJSONæ–‡ä»¶")
        sys.exit(1)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    for file_path in files_to_merge:
        if not Path(file_path).exists():
            print(f"é”™è¯¯: æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
            sys.exit(1)
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºmulti_model_answerç±»å‹æ–‡ä»¶
    is_multi_model_file = any('multi_model_answer' in str(f) for f in files_to_merge)
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºgradeç±»å‹æ–‡ä»¶
    is_grade_file = any('grade' in str(f).lower() for f in files_to_merge)
    
    print(f"å‡†å¤‡åˆå¹¶ {len(files_to_merge)} ä¸ªJSONæ–‡ä»¶:")
    for i, file_path in enumerate(files_to_merge, 1):
        print(f"  {i}. {file_path}")
    print()
    
    # åŠ è½½JSONæ–‡ä»¶
    json_data = load_json_files(files_to_merge)
    
    # ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶çš„é—®é¢˜æ•°é‡
    file_stats = []
    for i, data in enumerate(json_data):
        if isinstance(data, dict) and 'questions' in data:
            question_count = len(data['questions'])
            file_stats.append((files_to_merge[i].name, question_count))
    
    # æ£€æµ‹åˆå¹¶ç±»å‹
    merge_type = detect_merge_type(json_data)
    
    if merge_type == 'unknown':
        print("é”™è¯¯: æ— æ³•è¯†åˆ«JSONæ•°æ®æ ¼å¼ã€‚è¯·ç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯ç›¸åŒçš„æ ¼å¼ï¼š")
        print("1. å­—å…¸åˆ—è¡¨æ ¼å¼: [{dict1, dict2}, {dict3, dict4}]")
        print("2. åŒ…å«detailed_resultså­—æ®µçš„å­—å…¸æ ¼å¼")
        print("3. åŒ…å«questionså­—æ®µçš„å­—å…¸æ ¼å¼")
        print("4. åŒ…å«statisticså’Œdetailed_resultsçš„è¯„åˆ†æ–‡ä»¶æ ¼å¼")
        sys.exit(1)
    
    # æ‰§è¡Œåˆå¹¶
    if merge_type == 'list':
        print("æ£€æµ‹åˆ°å­—å…¸åˆ—è¡¨æ ¼å¼ï¼Œæ­£åœ¨åˆå¹¶...")
        merged_result = merge_dict_lists(json_data)
        print(f"åˆå¹¶å®Œæˆï¼Œå…±åˆå¹¶äº† {len(merged_result)} ä¸ªå­—å…¸é¡¹")
        
    elif merge_type == 'grade':
        print("æ£€æµ‹åˆ°è¯„åˆ†æ–‡ä»¶æ ¼å¼ï¼Œæ­£åœ¨åˆå¹¶...")
        merged_result = merge_grade_files(json_data)
        total_items = len(merged_result.get('detailed_results', []))
        
        # æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        for i, data in enumerate(json_data):
            filename = files_to_merge[i].name
            question_count = len(data.get('detailed_results', []))
            avg_score = data.get('statistics', {}).get('total_average_100', 0)
            print(f"  - {filename}: {question_count} ä¸ªé—®é¢˜, å¹³å‡åˆ†: {avg_score:.2f}")
        
        # æ‰“å°åˆå¹¶åçš„ç»Ÿè®¡
        if 'statistics' in merged_result:
            stats = merged_result['statistics']
            print(f"\nğŸ“Š åˆå¹¶åç»Ÿè®¡:")
            print(f"  - æ€»é—®é¢˜æ•°: {stats['total_questions']}")
            print(f"  - æœ‰æ•ˆè¯„åˆ†: {stats['valid_grades']}")
            print(f"  - å¹³å‡åˆ†: {stats.get('total_average_100', 0):.2f}")
            print(f"\nğŸ“Š åˆ†æ•°åˆ†å¸ƒ:")
            for range_key, count in stats['score_distribution'].items():
                print(f"  - {range_key}: {count} ä¸ª")
    
    elif merge_type == 'detailed_results':
        print("æ£€æµ‹åˆ°åŒ…å«detailed_resultsçš„å­—å…¸æ ¼å¼ï¼Œæ­£åœ¨åˆå¹¶...")
        merged_result = merge_detailed_results(json_data)
        total_items = len(merged_result.get('detailed_results', []))
        print(f"åˆå¹¶å®Œæˆï¼Œdetailed_resultsä¸­å…±æœ‰ {total_items} ä¸ªé¡¹ç›®")
        
    elif merge_type == 'questions':
        print("æ£€æµ‹åˆ°åŒ…å«questionsçš„å­—å…¸æ ¼å¼ï¼Œæ­£åœ¨åˆå¹¶...")
        merged_result = merge_questions(json_data)
        total_questions = len(merged_result.get('questions', {}))
        
        # æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        for filename, count in file_stats:
            print(f"  - {filename}: {count} ä¸ªé—®é¢˜")
        print(f"  - åˆå¹¶åæ€»è®¡: {total_questions} ä¸ªé—®é¢˜")
        
        # å¦‚æœæ˜¯multi_model_answeræ–‡ä»¶ä¸”å¯ç”¨äº†æ£€æŸ¥ï¼Œè¿›è¡Œæ¨¡å‹å®Œæ•´æ€§æ£€æŸ¥
        if is_multi_model_file and check_model_completeness and merge_type == 'questions':
            print("\nğŸ” æ£€æŸ¥æ¨¡å‹ç­”æ¡ˆå®Œæ•´æ€§...")
            print(f"å¿…éœ€çš„æ¨¡å‹: {', '.join(required_models)}")
            
            all_valid, missing_info, incomplete_questions = check_model_answers(merged_result.get('questions', {}), required_models)
            
            if all_valid:
                print("\nâœ… æ‰€æœ‰é—®é¢˜éƒ½åŒ…å«å¿…éœ€çš„æ¨¡å‹ç­”æ¡ˆï¼")
            else:
                print(f"\nâš ï¸  å‘ç° {len(missing_info)} ä¸ªä¸å®Œæ•´çš„é—®é¢˜")
                
                # ç®€æ´æ˜¾ç¤ºç¼ºå¤±çš„é—®é¢˜
                print("\nä¸å®Œæ•´é—®é¢˜åˆ—è¡¨:")
                for i, info in enumerate(missing_info[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"{i}. {info['question'][:60]}...")
                    print(f"   ç¼ºå¤±: {', '.join(info['missing_models'])}")
                
                if len(missing_info) > 10:
                    print(f"\n... è¿˜æœ‰ {len(missing_info) - 10} ä¸ªä¸å®Œæ•´çš„é—®é¢˜")
                
                # å¦‚æœéœ€è¦å°†ä¸å®Œæ•´çš„é¢˜ç›®å•ç‹¬ä¿å­˜
                if save_incomplete_separately and not preview_only:
                    # åˆ†ç¦»å®Œæ•´å’Œä¸å®Œæ•´çš„é—®é¢˜
                    complete_questions, incomplete_questions = separate_complete_incomplete_questions(
                        merged_result.get('questions', {}), required_models
                    )
                    
                    # æ›´æ–°merged_resultï¼Œåªä¿ç•™å®Œæ•´çš„é—®é¢˜
                    merged_result['questions'] = complete_questions
                    print(f"\nå°†æŠŠ {len(complete_questions)} ä¸ªå®Œæ•´çš„é—®é¢˜ä¿å­˜åˆ°ä¸»æ–‡ä»¶")
                    print(f"å°†æŠŠ {len(incomplete_questions)} ä¸ªä¸å®Œæ•´çš„é—®é¢˜ä¿å­˜åˆ°å•ç‹¬æ–‡ä»¶")
                    
                    # ä¿å­˜ä¸å®Œæ•´çš„é—®é¢˜
                    save_incomplete_questions(incomplete_questions, missing_info, incomplete_output_file)
                
                if not preview_only and not save_incomplete_separately:
                    response = input("\næ˜¯å¦ç»§ç»­ä¿å­˜æ–‡ä»¶ï¼ˆåŒ…å«ä¸å®Œæ•´çš„é—®é¢˜ï¼‰ï¼Ÿ(y/n): ")
                    if response.lower() != 'y':
                        print("å·²å–æ¶ˆä¿å­˜æ“ä½œ")
                        sys.exit(0)
    
    # é‡å‘½ådefaultå­—æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
    if rename_default_fields_flag:
        merged_result = rename_default_fields(merged_result)
    
    # é¢„è§ˆæˆ–ä¿å­˜ç»“æœ
    if preview_only:
        print("\nâœ… é¢„è§ˆæ¨¡å¼å®Œæˆ")
        print_merge_summary(merged_result, merge_type, len(files_to_merge))
    else:
        save_json(merged_result, output_file)
        print("\nâœ… åˆå¹¶æˆåŠŸå®Œæˆï¼")
        print_merge_summary(merged_result, merge_type, len(files_to_merge))


def print_merge_summary(merged_result: Union[List[Dict], Dict], merge_type: str, file_count: int):
    """
    æ‰“å°åˆå¹¶ç»“æœçš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        merged_result: åˆå¹¶åçš„ç»“æœ
        merge_type: åˆå¹¶ç±»å‹
        file_count: åˆå¹¶çš„æ–‡ä»¶æ•°é‡
    """
    if merge_type == 'questions':
        questions = merged_result.get('questions', {})
        total_questions = len(questions)
        
        # ç»Ÿè®¡æ¨¡å‹æ•°é‡
        model_count = set()
        for question_data in questions.values():
            if 'answers' in question_data:
                for model_name in question_data['answers'].keys():
                    model_count.add(model_name)
        
        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"  - åˆå¹¶æ–‡ä»¶æ•°: {file_count} ä¸ª")
        print(f"  - æ€»é—®é¢˜æ•°: {total_questions} ä¸ª")
        print(f"  - æ¶‰åŠæ¨¡å‹æ•°: {len(model_count)} ä¸ª")
    elif merge_type == 'grade':
        if 'statistics' in merged_result:
            stats = merged_result['statistics']
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"  - åˆå¹¶æ–‡ä»¶æ•°: {file_count} ä¸ª")
            print(f"  - æ€»é—®é¢˜æ•°: {stats['total_questions']} ä¸ª")
            print(f"  - æœ‰æ•ˆè¯„åˆ†: {stats['valid_grades']} ä¸ª")
            print(f"  - å¤±è´¥è¯„åˆ†: {stats['failed_grades']} ä¸ª")
            print(f"  - æ€»å¹³å‡åˆ†: {stats.get('total_average_100', 0):.2f} åˆ†")
    else:
        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"  - åˆå¹¶æ–‡ä»¶æ•°: {file_count} ä¸ª")
        print(f"  - æ•°æ®æ ¼å¼: {merge_type}")


if __name__ == "__main__":

    main()   
