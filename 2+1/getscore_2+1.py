#!/usr/bin/env python
# coding: utf-8
"""
fusion_reply_grade.py
------------------------------------
è¯»å–èåˆç­”æ¡ˆ JSONï¼Œå¯¹ fusion_reply è‡ªåŠ¨æ‰“åˆ†å¹¶æŒç»­ä¿å­˜è¿›åº¦ã€‚
"""

import json, re, os, time
from pathlib import Path
from typing import List, Dict, Any, Tuple
import httpx
from openai import OpenAI
from tqdm import tqdm

# ========== æ–‡ä»¶è·¯å¾„é…ç½® (æ–¹ä¾¿ä¿®æ”¹) ==========================================
INPUT_PATH = r"D:\project7\MM\result\2+1\doubao-pro-32k_answers_2+1-2-7800-8100.json"
OUTPUT_DIR = r"D:\project7\MM\result"
OUTPUT_FILENAME = "grades_doubao-pro-256k_answers_2+1-2-7800-8100.json"  # è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶å

# ========== å…¶ä»–é…ç½®é€‰é¡¹ =====================================================
SAVE_INTERVAL = 1  # æ¯ N é¢˜ä¿å­˜ä¸€æ¬¡

# ========== OpenAI åˆå§‹åŒ– ====================================================
httpx_client = httpx.Client(verify=False)
os.environ["OPENAI_API_KEY"]  = "sk-TlCq2TfX7oLuXzZMD1A3681285A2460bA26b6f0cEa5517Aa"
os.environ["OPENAI_BASE_URL"] = "https://vir.vimsai.com/v1"
client = OpenAI(http_client=httpx_client)

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
Path(OUTPUT_DIR).mkdir(exist_ok=True, parents=True)

# ========== Prompt æ¨¡æ¿ =====================================================
PROMPT_TMPL = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šç­”é¢˜è¯„å®¡å‘˜ï¼Œè¯·å¯¹ä»¥ä¸‹ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼ŒæŒ‰ç…§ä»¥ä¸‹ 5 ä¸ªç»´åº¦æ‰“åˆ†ï¼š
1. é€»è¾‘æ€§   2. æ·±åº¦   3. åˆ›æ–°æ€§   4. å‡†ç¡®æ€§   5. å®Œæ•´æ€§
æ¯ç»´åº¦æ»¡åˆ† 5ï¼Œæ€»åˆ† 25ã€‚

è¯„åˆ†æ ¼å¼ç¤ºä¾‹ï¼ˆä¸¥æ ¼ç…§æŠ„æ•°å­—å’Œç©ºæ ¼ï¼‰ï¼š
15 3 3 3 3 3
ï¼ˆæ­¤è¡Œåé¢ç´§è·Ÿè¯„åˆ†ç†ç”±æ®µè½ï¼‰

### é—®é¢˜
{question}

### å›ç­”
{answer}

### è¾“å‡ºè¦æ±‚
- ç¬¬ä¸€è¡Œ **åªå†™ 6 ä¸ªæ•°å­—**ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œé¡ºåºæ˜¯ï¼šæ€»åˆ† é€»è¾‘ æ·±åº¦ åˆ›æ–° å‡†ç¡® å®Œæ•´
- ä¸è¦å†™ä»»ä½•æ–‡å­—ã€å•ä½æˆ–æ ‡ç‚¹
- ç¬¬äºŒè¡Œå¼€å§‹å†™è¯¦ç»†è¯„åˆ†ç†ç”±ï¼ˆè‡³å°‘ 2 æ®µï¼‰

1. é€»è¾‘æ€§ â€”â€” è®ºè¯ç»“æ„ã€å› æœé“¾æ¡æ˜¯å¦ä¸¥è°¨ï¼›  
2. æ·±åº¦   â€”â€” æ˜¯å¦å¼•ç”¨å­¦æœ¯æ¦‚å¿µ / æ•°æ® / å¤šè§’åº¦åˆ†æï¼›  
3. åˆ›æ–°æ€§ â€”â€” æ˜¯å¦æå‡ºæ–°è§‚ç‚¹æˆ–éé™ˆè¯æ»¥è°ƒçš„æ´è§ï¼›  
4. å‡†ç¡®æ€§ â€”â€” äº‹å®ã€æ•°æ®ã€æ¦‚å¿µæ˜¯å¦æ­£ç¡®ï¼›  
5. å®Œæ•´æ€§ â€”â€” æ˜¯å¦å……åˆ†å›ç­”é¢˜å¹²æ‰€æœ‰è¦ç‚¹ã€‚

**æ‰“åˆ†ç¡¬æ€§è§„åˆ™**ï¼ˆä¸€å®šè¦æ‰§è¡Œ,è¯·è°¨æ…æ‰“é«˜åˆ†ï¼‰ï¼š  
| å•ç»´å¾—åˆ† | è¯„ä»·åŸºå‡†ï¼ˆç¤ºä¾‹ï¼‰ |  
|----------|-----------------|  
| 5 | å‡ ä¹æ— ç¼ºé™·ï¼Œä»…å¯æŒ‘ç»†èŠ‚ |  
| 4  | æœ‰ 1â€“2 å¤„è½»å¾®ç¼ºé™· |  
| 3  | å‡ºç° **æ˜æ˜¾ç¼ºé™·** æˆ–é—æ¼è¦ç‚¹ |  
| 2  | å¤šå¤„ç¼ºé™·ï¼Œè®ºè¯/äº‹å®é”™è¯¯ >2 å¤„ |  
| 0â€“1  | å…³é”®é€»è¾‘ä¸æˆç«‹ï¼Œæˆ–äº‹å®é”™è¯¯ä¸¥é‡ |
ä¸¥æ ¼éµå®ˆæ ¼å¼ï¼Œç°åœ¨å¼€å§‹ï¼š
"""

# ---------------------------------------------------------------------------
def read_json_file(file_path: str) -> List[Dict[str, Any]]:
    """è¯»å– JSON æ–‡ä»¶"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    return []

# ---------------------------------------------------------------------------
def load_existing_results(output_file: Path) -> Tuple[Dict[str, Any] | None, set]:
    """åŠ è½½å·²æœ‰è¯„åˆ†è¿›åº¦"""
    if output_file.exists():
        try:
            with open(output_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            done = {r["question"] for r in data.get("detailed_results", [])}
            print(f"ğŸ“‚ å·²æœ‰è¿›åº¦ï¼š{len(done)} é¢˜")
            return data, done
        except Exception as e:
            print(f"âš ï¸ è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
    return None, set()

# ---------------------------------------------------------------------------
def save_progress(data: Dict[str, Any], output_file: Path):
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜è‡³ {output_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

# ---------------------------------------------------------------------------
def parse_response(raw: str) -> Tuple[Dict[str, int], str]:
    """è§£æ GPT è¾“å‡º"""
    keys = ["total", "logic", "depth", "innovation", "accuracy", "completeness"]
    lines = [l.strip() for l in raw.splitlines() if l.strip()]

    # æ‰¾åˆ†æ•°å­—ä¸²
    score_line = next((l for l in lines if len(re.findall(r"\d+", l)) >= 6), None)
    if not score_line:
        raise ValueError("æ‰¾ä¸åˆ°å®Œæ•´åˆ†æ•°è¡Œ")
    nums = list(map(int, re.findall(r"\d+", score_line)[:6]))

    commentary = "\n".join(lines[lines.index(score_line) + 1:]).strip()
    if not commentary:
        raise ValueError("ç¼ºå°‘è¯„åˆ†ç†ç”±")

    return dict(zip(keys, nums)), commentary

# ---------------------------------------------------------------------------
def ask_and_parse(prompt: str,
                  model: str = "gpt-4o",
                  max_attempts: int = 6,
                  backoff_base: int = 2):
    for attempt in range(1, max_attempts + 1):
        try:
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )
            raw = resp.choices[0].message.content.strip()
            scores, detail = parse_response(raw)
            return scores, detail, raw
        except Exception as e:
            wait = backoff_base ** attempt
            print(f"âš ï¸ ç¬¬ {attempt}/{max_attempts} æ¬¡å¤±è´¥: {e}ï¼Œ{wait}s åé‡è¯•")
            time.sleep(wait)
    return None

# ---------------------------------------------------------------------------
def grade_single(question: str, answer: str, trials: int = 3):
    prompt = PROMPT_TMPL.format(question=question, answer=answer)
    all_scores, all_cmts, raws = [], [], []

    for t in range(trials):
        res = ask_and_parse(prompt)
        if not res:
            print(f"  ç¬¬ {t+1} æ¬¡è¯„åˆ†å¤±è´¥")
            continue
        score, cmt, raw = res
        all_scores.append(score); all_cmts.append(cmt); raws.append(raw)
        print(f"  ç¬¬ {t+1} æ¬¡å¾—åˆ†ï¼š{score['total']}/50")

    if not all_scores:
        return None

    avg = {k: round(sum(s[k] for s in all_scores) / len(all_scores), 2)
           for k in all_scores[0]}
    avg100 = round(avg["total"] * 2, 2)

    return {
        "question": question,
        "avg_scores": avg,
        "avg_score_100": avg100,
        "num_valid_trials": len(all_scores),
        "all_scores": all_scores,
        "all_commentaries": all_cmts,
        "all_gpt_raws": raws
    }

# ---------------------------------------------------------------------------
def grade_fusion_replies(records: List[Dict[str, Any]]):
    print(f"\n===== è¯„åˆ† fusion_reply =====")
    
    # ä½¿ç”¨é…ç½®çš„è¾“å‡ºæ–‡ä»¶å
    output_file = Path(OUTPUT_DIR) / OUTPUT_FILENAME
    
    prev, done_set = load_existing_results(output_file)
    results = prev.get("detailed_results", []) if prev else []

    # ç­›é€‰æœ‰ fusion_reply çš„è®°å½•
    items = [d for d in records if "fusion_reply" in d and d["fusion_reply"]]
    pending = [d for d in items if d["question"] not in done_set]
    
    print(f"å…±æœ‰ {len(items)} é¢˜ | å¾…è¯„åˆ† {len(pending)} é¢˜")

    # ä¸»å¾ªç¯
    all_totals, all_totals100 = [], []

    # è¡¥å…¥æ—§æˆç»©
    if prev:
        all_totals = [r["avg_scores"]["total"] for r in results]
        all_totals100 = [r["avg_score_100"] for r in results]

    for idx, item in enumerate(pending, 1):
        q = item["question"]
        a = item["fusion_reply"]
        
        print(f"\n[{idx}/{len(pending)}] {q[:40]}...")
        res = grade_single(q, a)
        
        if res:
            # ä¿å­˜é¢å¤–çš„å…ƒæ•°æ®
            res["type"] = "fusion_reply"
            if "third_model" in item:
                res["third_model"] = item["third_model"]
            if "A1_third_answer" in item:
                res["has_third_answer"] = True
            if "A2_combination_reply" in item:
                res["has_combination_reply"] = True
                
            results.append(res)
            all_totals.append(res["avg_scores"]["total"])
            all_totals100.append(res["avg_score_100"])

        if idx % SAVE_INTERVAL == 0:
            stats = {
                "type": "fusion_reply",
                "input_file": INPUT_PATH,
                "total_questions": len(items),
                "valid_grades": len(all_totals),
                "total_average": round(sum(all_totals)/len(all_totals), 2),
                "total_average_100": round(sum(all_totals100)/len(all_totals100), 2)
            }
            save_progress({"statistics": stats, "detailed_results": results}, output_file)

    # æœ€ç»ˆç»Ÿè®¡
    if all_totals:
        stats = {
            "type": "fusion_reply",
            "input_file": INPUT_PATH,
            "total_questions": len(items),
            "valid_grades": len(all_totals),
            "total_average": round(sum(all_totals)/len(all_totals), 2),
            "total_average_100": round(sum(all_totals100)/len(all_totals100), 2)
        }
        save_progress({"statistics": stats, "detailed_results": results}, output_file)
        print(f"\nğŸ“Š fusion_reply å¹³å‡ {stats['total_average']}/50 "
              f"(ç™¾åˆ†åˆ¶ {stats['total_average_100']})")

# ---------------------------------------------------------------------------
def main():
    data = read_json_file(INPUT_PATH)
    if not data:
        return
    
    grade_fusion_replies(data)

# ---------------------------------------------------------------------------
if __name__ == "__main__":
    main()