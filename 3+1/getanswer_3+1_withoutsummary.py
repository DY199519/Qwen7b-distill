#!/usr/bin/env python
# coding: utf-8
"""
multmm2_run234.py
-----------------
è¯»å–å¸¦æœ‰combinationå­—æ®µçš„prompt CSVæ–‡ä»¶ï¼Œæ‰§è¡Œæ¨¡å‹è°ƒç”¨ã€‚
ä¸ä¿å­˜è¿›åº¦ï¼Œæ¯é“é¢˜éƒ½å»ç­”æ¡ˆæ–‡ä»¶é‡Œå®æ—¶æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ã€‚
è¾“å‡º JSON ç»Ÿä¸€å†™å…¥ OUTPUT_DIRã€‚
å¢å¼ºåŠŸèƒ½ï¼š
- æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
- å›ç­”è´¨é‡éªŒè¯
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
- æ™ºèƒ½é‡è¯•æœºåˆ¶
"""

import csv, json, time
from pathlib import Path
from openai import OpenAI
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import re

# ========== 0. è·¯å¾„é…ç½® =======================================================
# è¾“å‡ºæ–‡ä»¶è·¯å¾„ - æ”¾åˆ°æœ€å‰é¢
OUTPUT_FILE = Path(r"D:\project7\MM\result\3+1\deepseek_answers_without_summary3+1-9400-10000.json")

BASE_DIR_1   = Path(r"D:\project7\MM\3+1")           # æ•°æ®æ–‡ä»¶æ‰€åœ¨æ ¹ç›®å½•
BASE_DIR = Path(r"D:\project7\prompt")
OUTPUT_DIR = Path(r"D:\project7\MM\result")            # <-- åªæ”¹è¿™é‡Œå³å¯æ¢è¾“å‡ºä½ç½®
OUTPUT_DIR_1 = Path(r"D:\project7\MM\result\3+1")            # <-- åªæ”¹è¿™é‡Œå³å¯æ¢è¾“å‡ºä½ç½®

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR_1.mkdir(parents=True, exist_ok=True)

# ä¿®æ”¹ä¸ºè¯»å–å¸¦combinationçš„CSVæ–‡ä»¶
PROMPT_CSV = OUTPUT_DIR / "final_prompt_3+1-9400-10000.csv"

GROUPED_JSON = OUTPUT_DIR / "multi_model_answer9400-10000.json"

# è¿è¡Œæ—¥å¿—æ–‡ä»¶
RUN_LOG = OUTPUT_DIR_1 / f"run_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

# ========== 1. æ¨¡å‹åˆ—è¡¨ =======================================================
MODEL_CFGS = [
    {
        "model_name": "deepseek-v3",
        "api_key": "sk-TlCq2TfX7oLuXzZMD1A3681285A2460bA26b6f0cEa5517Aa",
        "base_url": "https://usa.vimsai.com/v1",
        "timeout": 60,  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        "max_retry": 3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
    }
    # {
    #     "model_name": "qwen2.5-72b-instruct",
    #     "api_key": "sk-N4rH9BjW8xR1akf0C01426F958D74c9d97Bd7a131a09B5B4",
    #     "base_url": "https://api.vansai.cn/v1",
    #     "timeout": 60,
    #     "max_retry": 3,
    # },
]

# ========== 2. ç­”æ¡ˆéªŒè¯ç±» ====================================================
class AnswerValidator:
    """ç­”æ¡ˆéªŒè¯å™¨"""
    
    # æœ€å°ç­”æ¡ˆé•¿åº¦
    MIN_ANSWER_LENGTH = 5
    
    # é”™è¯¯æ¨¡å¼
    ERROR_PATTERNS = [
        r'^error:',
        r'^exception:',
        r'^\s*$',
        r'^null$',
        r'^undefined$',
        r'^N/A$',
        r'request failed',
        r'rate limit',
        r'timeout',
    ]
    
    @classmethod
    def validate_answer(cls, answer: str, question: str = "") -> Tuple[bool, List[str]]:
        """éªŒè¯ç­”æ¡ˆæ˜¯å¦æœ‰æ•ˆ"""
        issues = []
        
        if not answer:
            issues.append("ç­”æ¡ˆä¸ºç©º")
            return False, issues
        
        if not isinstance(answer, str):
            issues.append(f"ç­”æ¡ˆç±»å‹é”™è¯¯: {type(answer)}")
            return False, issues
        
        answer = answer.strip()
        
        # é•¿åº¦æ£€æŸ¥
        if len(answer) < cls.MIN_ANSWER_LENGTH:
            issues.append(f"ç­”æ¡ˆè¿‡çŸ­ ({len(answer)} å­—ç¬¦)")
        
        # é”™è¯¯æ¨¡å¼æ£€æŸ¥
        for pattern in cls.ERROR_PATTERNS:
            if re.search(pattern, answer, re.IGNORECASE):
                issues.append(f"åŒ¹é…é”™è¯¯æ¨¡å¼: {pattern}")
                return False, issues
        
        return len(issues) == 0, issues

# ========== 3. æ—¥å¿—è®°å½•å™¨ ====================================================
class Logger:
    """ç®€å•çš„æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_file: Path):
        self.log_file = log_file
        self.start_time = datetime.now()
        self._write(f"=== è¿è¡Œå¼€å§‹: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')} ===\n")
    
    def _write(self, message: str):
        """å†™å…¥æ—¥å¿—"""
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"{message}\n")
    
    def info(self, message: str):
        """è®°å½•ä¿¡æ¯"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        self._write(f"[{timestamp}] INFO: {message}")
        print(f"ğŸ“ {message}")
    
    def error(self, message: str):
        """è®°å½•é”™è¯¯"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        self._write(f"[{timestamp}] ERROR: {message}")
        print(f"âŒ {message}")
    
    def warning(self, message: str):
        """è®°å½•è­¦å‘Š"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        self._write(f"[{timestamp}] WARNING: {message}")
        print(f"âš ï¸ {message}")
    
    def summary(self, stats: dict):
        """è®°å½•ç»Ÿè®¡æ‘˜è¦"""
        elapsed = datetime.now() - self.start_time
        self._write(f"\n=== è¿è¡Œç»Ÿè®¡ ===")
        self._write(f"æ€»è€—æ—¶: {elapsed}")
        for key, value in stats.items():
            self._write(f"{key}: {value}")
        self._write("=" * 50)

# ========== 4. å·¥å…·å‡½æ•° =======================================================
def find_existing_answer(question: str, output_file: Path) -> dict:
    """
    åœ¨è¾“å‡ºæ–‡ä»¶ä¸­æŸ¥æ‰¾æŒ‡å®šé—®é¢˜çš„ç­”æ¡ˆ
    è¿”å›: æ‰¾åˆ°çš„ç­”æ¡ˆé¡¹ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
    """
    if not output_file.exists():
        return None
    
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        for item in data:
            if item.get('question') == question:
                return item
                
    except Exception as e:
        print(f"âŒ è¯»å–ç­”æ¡ˆæ–‡ä»¶å¤±è´¥: {e}")
        
    return None

def is_answer_complete_and_valid(item: dict) -> Tuple[bool, List[str]]:
    """
    æ£€æŸ¥ç­”æ¡ˆé¡¹æ˜¯å¦å®Œæ•´ä¸”æœ‰æ•ˆ
    è¿”å›: (æ˜¯å¦æœ‰æ•ˆ, é—®é¢˜åˆ—è¡¨)
    """
    if not item:
        return False, ["ç­”æ¡ˆé¡¹ä¸ºç©º"]
    
    issues = []
    
    # æ£€æŸ¥direct_reply
    if not item.get('direct_reply'):
        issues.append("ç¼ºå°‘direct_reply")
    else:
        is_valid, sub_issues = AnswerValidator.validate_answer(item['direct_reply'])
        if not is_valid:
            issues.extend([f"direct_reply: {issue}" for issue in sub_issues])
    
    # æ£€æŸ¥default_reply
    if not item.get('default_reply'):
        issues.append("ç¼ºå°‘default_reply")
    else:
        is_valid, sub_issues = AnswerValidator.validate_answer(item['default_reply'])
        if not is_valid:
            issues.extend([f"default_reply: {issue}" for issue in sub_issues])
    
    return len(issues) == 0, issues

def ask(api: OpenAI, model: str, prompt: str, logger: Logger, 
        timeout: int = 60, max_retry: int = 3, pause: float = 2.0) -> Tuple[str, bool, List[str]]:
    """
    è°ƒç”¨æ¨¡å‹API
    è¿”å›: (ç­”æ¡ˆ, æ˜¯å¦æˆåŠŸ, é”™è¯¯åˆ—è¡¨)
    """
    errors = []
    
    for i in range(1, max_retry + 1):
        try:
            # è®¾ç½®è¶…æ—¶
            rsp = api.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                timeout=timeout
            )
            answer = rsp.choices[0].message.content.strip()
            
            # éªŒè¯ç­”æ¡ˆ
            is_valid, issues = AnswerValidator.validate_answer(answer, prompt[:50])
            
            if is_valid and answer:
                return answer, True, []
            else:
                errors.append(f"ç¬¬{i}æ¬¡å°è¯• - ç­”æ¡ˆéªŒè¯å¤±è´¥: {', '.join(issues)}")
                logger.warning(f"ç­”æ¡ˆéªŒè¯å¤±è´¥: {issues}")
                
        except Exception as e:
            error_msg = f"ç¬¬{i}æ¬¡å°è¯•å¤±è´¥: {str(e)}"
            errors.append(error_msg)
            logger.error(error_msg)
        
        if i < max_retry:
            time.sleep(pause * i)  # é€’å¢ç­‰å¾…æ—¶é—´
    
    return "", False, errors

def append_to_file(item: dict, output_file: Path, logger: Logger):
    """
    å°†æ–°ç­”æ¡ˆè¿½åŠ åˆ°æ–‡ä»¶
    """
    try:
        # è¯»å–ç°æœ‰æ•°æ®
        if output_file.exists():
            with open(output_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            data = []
        
        # æ·»åŠ æ–°é¡¹
        data.append(item)
        
        # å†™å›æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"å·²ä¿å­˜ç­”æ¡ˆåˆ°æ–‡ä»¶ï¼ˆæ€»æ•°: {len(data)}ï¼‰")
        
    except Exception as e:
        logger.error(f"ä¿å­˜ç­”æ¡ˆå¤±è´¥: {e}")

def validate_csv_data(csv_path: Path, logger: Logger) -> bool:
    """éªŒè¯CSVæ•°æ®çš„å®Œæ•´æ€§"""
    try:
        with csv_path.open("r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            
            if not rows:
                logger.error("CSVæ–‡ä»¶ä¸ºç©º")
                return False
            
            # æ£€æŸ¥å¿…éœ€çš„åˆ—
            required_columns = ['question', 'prompt']
            missing_columns = [col for col in required_columns if col not in reader.fieldnames]
            if missing_columns:
                logger.error(f"CSVç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
                return False
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            empty_questions = 0
            empty_prompts = 0
            
            for row in rows:
                if not row.get('question', '').strip():
                    empty_questions += 1
                if not row.get('prompt', '').strip():
                    empty_prompts += 1
            
            if empty_questions > 0:
                logger.warning(f"å‘ç° {empty_questions} ä¸ªç©ºé—®é¢˜")
            if empty_prompts > 0:
                logger.warning(f"å‘ç° {empty_prompts} ä¸ªç©ºprompt")
            
            logger.info(f"CSVæ•°æ®éªŒè¯å®Œæˆï¼š{len(rows)} æ¡è®°å½•")
            return True
            
    except Exception as e:
        logger.error(f"CSVéªŒè¯å¤±è´¥ï¼š{e}")
        return False

# ========== 5. ä¸»æ‰§è¡Œå‡½æ•° =====================================================
def run_batch(model_cfg: dict, csv_path: Path):
    name = model_cfg["model_name"]
    logger = Logger(RUN_LOG)
    
    logger.info(f"å¼€å§‹è¿è¡Œæ¨¡å‹: {name}")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    
    # éªŒè¯CSVæ•°æ®
    if not validate_csv_data(csv_path, logger):
        logger.error("CSVæ•°æ®éªŒè¯å¤±è´¥ï¼Œé€€å‡ºè¿è¡Œ")
        return
    
    # åˆå§‹åŒ–API
    try:
        api = OpenAI(
            api_key=model_cfg["api_key"], 
            base_url=model_cfg["base_url"]
        )
    except Exception as e:
        logger.error(f"APIåˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # --- è¯»å– CSV ---
    questions = []
    question_prompts = {}  # ç›´æ¥å­˜å‚¨é—®é¢˜å’Œpromptçš„æ˜ å°„
    
    with csv_path.open("r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        logger.info(f"CSVåˆ—å: {reader.fieldnames}")
        
        for row in reader:
            q = row["question"]
            prompt = row["prompt"]
            question_prompts[q] = prompt
            questions.append(q)
    
    total_questions = len(questions)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "æ¨¡å‹": name,
        "æ€»é—®é¢˜æ•°": total_questions,
        "è·³è¿‡æ•°": 0,
        "æ–°ç”Ÿæˆæ•°": 0,
        "é‡æ–°ç”Ÿæˆæ•°": 0,
        "æˆåŠŸæ•°": 0,
        "å¤±è´¥æ•°": 0,
        "APIè°ƒç”¨æ¬¡æ•°": 0
    }
    
    logger.info(f"=== ğŸš€ {name} ===")
    logger.info(f"æ€»é—®é¢˜æ•°ï¼š{stats['æ€»é—®é¢˜æ•°']}")
    
    # é”™è¯¯è®°å½•
    failed_questions = []
    
    # å¤„ç†æ¯é“é¢˜
    for idx, q in enumerate(questions, 1):
        print(f"\n[{idx}/{total_questions}] æ£€æŸ¥é—®é¢˜: {q[:60]}â€¦")
        
        # æŸ¥æ‰¾ç°æœ‰ç­”æ¡ˆ
        existing_item = find_existing_answer(q, OUTPUT_FILE)
        
        if existing_item:
            # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦å®Œæ•´ä¸”æœ‰æ•ˆ
            is_valid, issues = is_answer_complete_and_valid(existing_item)
            
            if is_valid:
                print(f"  âœ… è·³è¿‡ï¼ˆå·²æœ‰æœ‰æ•ˆç­”æ¡ˆï¼‰")
                stats['è·³è¿‡æ•°'] += 1
                continue
            else:
                print(f"  ğŸ”„ éœ€è¦é‡æ–°ç”Ÿæˆï¼ˆé—®é¢˜: {', '.join(issues)}ï¼‰")
                stats['é‡æ–°ç”Ÿæˆæ•°'] += 1
        else:
            print(f"  ğŸ†• ç”Ÿæˆæ–°ç­”æ¡ˆ")
            stats['æ–°ç”Ÿæˆæ•°'] += 1
        
        # ç”Ÿæˆç­”æ¡ˆ
        # direct/basic
        stats['APIè°ƒç”¨æ¬¡æ•°'] += 1
        direct_answer = ""
        
        # å°è¯•å¤šæ¬¡è·å–æœ‰æ•ˆç­”æ¡ˆ
        max_attempts = 5  # æœ€å¤šå°è¯•5æ¬¡
        attempt = 0
        success = False
        
        while attempt < max_attempts and not success:
            attempt += 1
            if attempt > 1:
                logger.info(f"ç¬¬ {attempt} æ¬¡å°è¯•ç”Ÿæˆdirectç­”æ¡ˆ...")
            
            # è·å–directç­”æ¡ˆ
            direct_answer, success, errors = ask(
                api, name, q, logger,
                timeout=model_cfg.get('timeout', 60),
                max_retry=model_cfg.get('max_retry', 3)
            )
            
            if success:
                break
            else:
                logger.warning(f"ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥: {errors}")
                if attempt < max_attempts:
                    time.sleep(5 * attempt)  # é€’å¢ç­‰å¾…æ—¶é—´
        
        if not success:
            failed_questions.append({
                'question': q,
                'type': 'direct',
                'errors': errors,
                'attempts': attempt
            })
            stats['å¤±è´¥æ•°'] += 1
            logger.error(f"é—®é¢˜ '{q[:50]}...' åœ¨ {attempt} æ¬¡å°è¯•åä»ç„¶å¤±è´¥")
            # å³ä½¿å¤±è´¥ä¹Ÿè®°å½•ï¼Œæ–¹ä¾¿åç»­å¤„ç†
            direct_answer = f"[ERROR after {attempt} attempts]"
        
        item = {
            "question": q, 
            "direct_prompt": q, 
            "direct_reply": direct_answer,
            "timestamp": datetime.now().isoformat(),
            "attempts": attempt
        }
        
        # å¤„ç† default prompt/reply
        if q in question_prompts:
            ptxt = question_prompts[q]
            print(f"  Â· å¤„ç† default prompt...")
            
            if ptxt:
                stats['APIè°ƒç”¨æ¬¡æ•°'] += 1
                
                # åŒæ ·å°è¯•å¤šæ¬¡
                default_attempt = 0
                default_success = False
                default_reply = ""
                
                while default_attempt < max_attempts and not default_success:
                    default_attempt += 1
                    if default_attempt > 1:
                        logger.info(f"default - ç¬¬ {default_attempt} æ¬¡å°è¯•...")
                    
                    default_reply, default_success, errors = ask(
                        api, name, ptxt, logger,
                        timeout=model_cfg.get('timeout', 60),
                        max_retry=model_cfg.get('max_retry', 3)
                    )
                    
                    if default_success:
                        break
                    else:
                        if default_attempt < max_attempts:
                            time.sleep(5 * default_attempt)
                
                if not default_success:
                    failed_questions.append({
                        'question': q,
                        'type': 'default',
                        'errors': errors,
                        'attempts': default_attempt
                    })
                    stats['å¤±è´¥æ•°'] += 1
                    default_reply = f"[ERROR after {default_attempt} attempts]"
            else:
                default_reply = ""
            
            item["default_prompt"] = ptxt
            item["default_reply"] = default_reply
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å›ç­”éƒ½è·å–æˆåŠŸ
        all_success = True
        for key in item:
            if key.endswith('_reply') and '[ERROR' in str(item.get(key, '')):
                all_success = False
                break
        
        if all_success:
            stats['æˆåŠŸæ•°'] += 1
        
        # è¿½åŠ åˆ°æ–‡ä»¶
        append_to_file(item, OUTPUT_FILE, logger)
        
        print(f"  âœ… å·²ä¿å­˜ç­”æ¡ˆ")
        
        # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
        processed = stats['è·³è¿‡æ•°'] + stats['æ–°ç”Ÿæˆæ•°'] + stats['é‡æ–°ç”Ÿæˆæ•°']
        success_rate = (stats['æˆåŠŸæ•°'] / (stats['æ–°ç”Ÿæˆæ•°'] + stats['é‡æ–°ç”Ÿæˆæ•°']) * 100) if (stats['æ–°ç”Ÿæˆæ•°'] + stats['é‡æ–°ç”Ÿæˆæ•°']) > 0 else 100
        logger.info(f"è¿›åº¦: {processed}/{total_questions} (è·³è¿‡: {stats['è·³è¿‡æ•°']}, æ–°ç”Ÿæˆ: {stats['æ–°ç”Ÿæˆæ•°']}, é‡æ–°ç”Ÿæˆ: {stats['é‡æ–°ç”Ÿæˆæ•°']}, æˆåŠŸç‡: {success_rate:.1f}%)")

    # ä¿å­˜å¤±è´¥è®°å½•
    if failed_questions:
        failed_file = OUTPUT_DIR_1 / f"failed_questions_{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        failed_file.write_text(
            json.dumps(failed_questions, ensure_ascii=False, indent=2),
            encoding='utf-8'
        )
        logger.warning(f"å¤±è´¥è®°å½•å·²ä¿å­˜åˆ°: {failed_file}")
    
    # æ›´æ–°ç»Ÿè®¡
    stats['æœ€ç»ˆæˆåŠŸç‡'] = f"{(stats['æˆåŠŸæ•°'] / (stats['æ–°ç”Ÿæˆæ•°'] + stats['é‡æ–°ç”Ÿæˆæ•°']) * 100):.1f}%" if (stats['æ–°ç”Ÿæˆæ•°'] + stats['é‡æ–°ç”Ÿæˆæ•°']) > 0 else "100%"
    
    # è®°å½•æœ€ç»ˆç»Ÿè®¡
    logger.summary(stats)
    
    print(f"\nâœ… {name} å®Œæˆï¼")
    print(f"  Â· æ€»é¢˜æ•°: {stats['æ€»é—®é¢˜æ•°']}")
    print(f"  Â· è·³è¿‡: {stats['è·³è¿‡æ•°']}")
    print(f"  Â· æ–°ç”Ÿæˆ: {stats['æ–°ç”Ÿæˆæ•°']}")
    print(f"  Â· é‡æ–°ç”Ÿæˆ: {stats['é‡æ–°ç”Ÿæˆæ•°']}")
    print(f"  Â· æˆåŠŸ: {stats['æˆåŠŸæ•°']}")
    print(f"  Â· å¤±è´¥: {stats['å¤±è´¥æ•°']}")
    print(f"  Â· æˆåŠŸç‡: {stats['æœ€ç»ˆæˆåŠŸç‡']}")

# ========== 6. æ‰§è¡Œå¾ªç¯ =======================================================
print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
print(f"ğŸ“„ è¾“å…¥CSV: {PROMPT_CSV}")
print(f"ğŸ“ è¿è¡Œæ—¥å¿—: {RUN_LOG}")
print("-" * 60)

for cfg in MODEL_CFGS:
    run_batch(cfg, PROMPT_CSV)

print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_FILE}")
print(f"ğŸ“ è¿è¡Œæ—¥å¿—: {RUN_LOG}")