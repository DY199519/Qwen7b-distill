#!/usr/bin/env python
# coding: utf-8
"""
multmm2_run2plus2_topic_first_modified_v2_simplified.py
----------------------------------------
ç®€åŒ–ç‰ˆï¼šåªå¤„ç†ç¬¬ä¸€ç»„å›ç­”ç»„åˆ
combination_1_A1A2_reply ä½œä¸º A1
combination_1_A1A3_reply ä½œä¸º A2
ä¿®æ”¹ç‰ˆï¼šæ·»åŠ ç­”æ¡ˆè´¨é‡æ£€æŸ¥åŠŸèƒ½
"""

import json, time
from pathlib import Path
from openai import OpenAI

# ===== 0. è·¯å¾„é…ç½® ===========================================================
BASE_DIR = Path(r"D:\project7\MM\result")
BASE_DIR_1 = Path(r"D:\project7\prompt")

OUTPUT_DIR = Path(r"D:\project7\MM\result")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# è¾“å‡ºæ–‡ä»¶å®šä¹‰ï¼ˆç§»åˆ°æœ€å‰é¢ï¼‰
OUTPUT_FILE = OUTPUT_DIR / "answer-2+2-2.json"

# è¯»å–åŒ…å«å„ç§å›ç­”çš„ JSON æ–‡ä»¶
ANSWER_FILE = BASE_DIR / "answer-2+2-1.json"
PROMPT_FILE = BASE_DIR_1 / "prompt-2+2-2.txt"
SAVE_INTERVAL = 10  # æ¯ N é¢˜ä¿å­˜ä¸€æ¬¡

# ç­”æ¡ˆè´¨é‡æ£€æŸ¥å‚æ•°
MIN_ANSWER_LENGTH = 10  # æœ€å°å­—æ•°è¦æ±‚
VALID_END_PUNCTUATION = {'.', 'ã€‚', '!', 'ï¼', '?', 'ï¼Ÿ', ')', 'ï¼‰', '"', '"', "'", "'"}  # æœ‰æ•ˆçš„ç»“å°¾æ ‡ç‚¹

# ===== 1. æ¨¡å‹è´¦æˆ·é…ç½® =======================================================
MODEL_CFGS = [
    {
        "model_name": "deepseek-v3",
        "api_key": "sk-N4rH9BjW8xR1akf0C01426F958D74c9d97Bd7a131a09B5B4",
        "base_url": "https://api.vansai.cn/v1",
    }
]

# ===== 2. è¯»å–æç¤ºè¯æ¨¡æ¿ ====================================================
def load_prompt_template(template_path: Path):
    """è¯»å–æç¤ºè¯æ¨¡æ¿æ–‡ä»¶"""
    try:
        with template_path.open("r", encoding="utf-8") as f:
            return f.read().strip()
    except Exception as e:
        print(f"âŒ è¯»å–æç¤ºè¯æ¨¡æ¿å¤±è´¥: {e}")
        # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
        return """é˜…è¯» å…¶ä»–ä¸¤ä¸ªæ¨¡å‹çš„æ€»ç»“å›ç­”A2 å¹¶å®Œå–„æ‚¨ä¹‹å‰çš„å›ç­”A1ã€‚å¦‚ä»æœ‰ç©ºç¼ºï¼Œå¯è¡¥å……ä½ çš„å¸¸è¯†æˆ–å…¬å¼€èµ„æ–™ï¼Œå¹¶ç”¨æ‹¬å·æ³¨æ˜æ¥æºï¼ˆå¸¸è¯†ï¼å…¬å¼€èµ„æ–™ï¼‰ã€‚
é—®é¢˜ï¼š
{q}
A1ï¼š
{A1}
A2ï¼š
{A2}
ã€ä»»åŠ¡è¯´æ˜ã€‘  
ä¸å±•ç¤ºä¸­é—´æå–è¿‡ç¨‹ã€‚å‰é¢ä¸å¸¦ä»»ä½•é“ºå«æ€§çš„è¯­å¥
ã€è¾“å‡ºè¦æ±‚ã€‘  
- æ¡ç†æ¸…æ™°ï¼Œå¯ä½¿ç”¨ç¼–å·æˆ–åˆ†æ®µï¼›  
- é¿å…èµ˜è¿°ï¼Œä¿æŒç®€ç»ƒã€‚"""

# åŠ è½½æç¤ºè¯æ¨¡æ¿
PROMPT_TEMPLATE = load_prompt_template(PROMPT_FILE)

# ===== 3. è¾…åŠ©å‡½æ•° ==========================================================

def check_answer_quality(answer: str) -> tuple[bool, str]:
    """
    æ£€æŸ¥ç­”æ¡ˆè´¨é‡
    è¿”å›: (æ˜¯å¦åˆæ ¼, é—®é¢˜æè¿°)
    """
    if not answer:
        return False, "ç­”æ¡ˆä¸ºç©º"
    
    # æ£€æŸ¥å­—æ•°
    if len(answer.strip()) < MIN_ANSWER_LENGTH:
        return False, f"ç­”æ¡ˆè¿‡çŸ­ï¼ˆå°‘äº{MIN_ANSWER_LENGTH}å­—ï¼‰"
    
    # æ£€æŸ¥ç»“å°¾æ ‡ç‚¹
    last_char = answer.strip()[-1] if answer.strip() else ''
    if last_char not in VALID_END_PUNCTUATION:
        return False, f"ç­”æ¡ˆæœªä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾ï¼ˆæœ€åå­—ç¬¦: '{last_char}'ï¼‰"
    
    return True, "åˆæ ¼"

def ask(api: OpenAI, model: str, prompt: str, retry: int = 3, pause: int = 2):
    """è°ƒç”¨æ¨¡å‹APIï¼Œå¹¶è¿›è¡Œè´¨é‡æ£€æŸ¥"""
    for i in range(retry):
        try:
            rsp = api.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                timeout=60,
            )
            txt = rsp.choices[0].message.content.strip()
            
            # æ£€æŸ¥ç­”æ¡ˆè´¨é‡
            is_valid, issue = check_answer_quality(txt)
            if not is_valid:
                print(f"  âš ï¸ ç­”æ¡ˆè´¨é‡é—®é¢˜: {issue}")
                if i < retry - 1:
                    print(f"  ğŸ”„ é‡è¯•ä¸­...")
                    time.sleep(pause)
                    continue
                else:
                    print(f"  âŒ å¤šæ¬¡å°è¯•åä»æœ‰è´¨é‡é—®é¢˜ï¼Œä½¿ç”¨å½“å‰ç»“æœ")
            
            return txt
            
        except Exception as e:
            print(f"âŒ {model} ç¬¬ {i+1} æ¬¡å¤±è´¥: {e}")
            time.sleep(pause)
    return ""

def load_progress(file: Path):
    """åŠ è½½å·²å¤„ç†çš„è¿›åº¦"""
    if not file.exists():
        return {}
    try:
        with file.open("r", encoding="utf-8") as f:
            data = json.load(f)
        return {row["question"]: row for row in data}
    except Exception as e:
        print(f"âš ï¸ è¯»å–è¿›åº¦å¤±è´¥: {e}")
        return {}

def save_progress(done_dict: dict, file: Path):
    """ä¿å­˜è¿›åº¦"""
    try:
        rows = list(done_dict.values())
        tmp = file.with_suffix(".tmp")
        tmp.write_text(json.dumps(rows, ensure_ascii=False, indent=2), "utf-8")
        tmp.replace(file)
        print(f"ğŸ’¾ ä¿å­˜ {file.name} ï¼ˆ{len(rows)} æ¡ï¼‰")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def load_answer_data(answer_path: Path):
    """è¯»å–åŒ…å«é—®é¢˜å’Œå›ç­”çš„ JSON æ–‡ä»¶"""
    data = {}
    
    if not answer_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {answer_path}")
        return data
        
    with answer_path.open("r", encoding="utf-8") as f:
        # åˆ¤æ–­æ–‡ä»¶æ˜¯ JSON æ•°ç»„è¿˜æ˜¯ JSON lines
        first_char = f.read(1)
        f.seek(0)
        if first_char == "[":
            entries = json.load(f)
        else:
            entries = [json.loads(line) for line in f if line.strip()]
    
    print(f"ğŸ“– è¯»å–åˆ° {len(entries)} æ¡è®°å½•")
    
    for i, entry in enumerate(entries):
        try:
            q = entry["question"]
            
            # ä» answers æ•°ç»„ä¸­æå–å›ç­”
            answers = entry.get("answers", [])
            
            # è°ƒè¯•ä¿¡æ¯ï¼ˆåªæ‰“å°ç¬¬ä¸€æ¡ï¼‰
            if i == 0:
                print(f"ğŸ” ç¬¬ä¸€æ¡è®°å½•çš„å­—æ®µ: {list(entry.keys())}")
                print(f"   âœ“ answers æ•°é‡: {len(answers)}")
            
            # ç¡®ä¿æœ‰è‡³å°‘ä¸¤ä¸ªç­”æ¡ˆ
            if len(answers) >= 2:
                # æå–å‰ä¸¤ä¸ªç­”æ¡ˆçš„ reply ä½œä¸º A1 å’Œ A2
                a1 = answers[0].get("reply", "")
                a2 = answers[1].get("reply", "")
                
                if a1 and a2:
                    data[q] = {"A1": a1, "A2": a2}
                    
        except (KeyError, IndexError) as e:
            print(f"âš ï¸ ç¬¬ {i+1} æ¡è®°å½•å¤„ç†å‡ºé”™: {e}")
            continue
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªé—®é¢˜çš„æ•°æ®")
    return data

# ===== 4. ä¸»å¤„ç†å‡½æ•° =========================================================
def process_questions(data, model_cfg):
    """å¤„ç†æ‰€æœ‰é—®é¢˜"""
    model_name = model_cfg["model_name"]
    api = OpenAI(api_key=model_cfg["api_key"], base_url=model_cfg["base_url"])
    
    # ä½¿ç”¨å…¨å±€å®šä¹‰çš„è¾“å‡ºæ–‡ä»¶
    done_dict = load_progress(OUTPUT_FILE)
    
    print(f"\nğŸ“Š {model_name} å·²å¤„ç† {len(done_dict)} é¢˜")
    
    processed = 0
    skipped = 0
    quality_issues = 0
    questions = sorted(data.keys())
    
    for qi, q in enumerate(questions, 1):
        print(f"\nğŸ“ [{qi}/{len(questions)}] {q[:60]}...")
        
        # å·²å¤„ç†è¿‡åˆ™è·³è¿‡
        if q in done_dict:
            print(f"  â­ï¸ å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
            skipped += 1
            continue
        
        # è·å– A1 å’Œ A2
        a1 = data[q]["A1"]
        a2 = data[q]["A2"]
        
        # æ„å»º prompt
        prompt = PROMPT_TEMPLATE.format(q=q, A1=a1, A2=a2)
        
        # è°ƒç”¨æ¨¡å‹
        print(f"  ğŸ¤– è°ƒç”¨ {model_name}")
        reply = ask(api, model_name, prompt)
        
        # æ£€æŸ¥èåˆå›ç­”çš„è´¨é‡
        is_valid, issue = check_answer_quality(reply)
        
        # ä¿å­˜ç»“æœ
        item = {
            "question": q,
            "A1": a1,
            "A2": a2,
            "fusion_prompt": prompt,
            "fusion_reply": reply,
        }
        
        if not is_valid:
            quality_issues += 1
            item["quality_issue"] = issue
        
        done_dict[q] = item
        processed += 1
        
        # å®šæœŸä¿å­˜
        if processed > 0 and processed % SAVE_INTERVAL == 0:
            print(f"\nğŸ’¾ è¾¾åˆ°ä¿å­˜é—´éš”ï¼Œä¿å­˜è¿›åº¦...")
            save_progress(done_dict, OUTPUT_FILE)
    
    # æœ€ç»ˆä¿å­˜
    save_progress(done_dict, OUTPUT_FILE)
    
    return processed, skipped, quality_issues

# ===== 5. è„šæœ¬å…¥å£ ==========================================================
if __name__ == "__main__":
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print(f"ğŸ“ ç­”æ¡ˆè´¨é‡è¦æ±‚: æœ€å°‘{MIN_ANSWER_LENGTH}å­—ï¼Œéœ€ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾")
    
    # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
    if not PROMPT_FILE.exists():
        print(f"âš ï¸ æç¤ºè¯æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {PROMPT_FILE}")
        print("ğŸ“ è¯·åˆ›å»º prompt-2+2-2.txt æ–‡ä»¶ï¼ŒåŒ…å« {q}ã€{A1} å’Œ {A2} å ä½ç¬¦")
    else:
        print(f"âœ… å·²åŠ è½½æç¤ºè¯æ¨¡æ¿: {PROMPT_FILE}")
    
    # è¯»å–ç­”æ¡ˆæ•°æ®
    data = load_answer_data(ANSWER_FILE)
    
    if not data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œé€€å‡º")
        exit(1)
    
    print(f"ğŸ“š æ€»é¢˜ç›®æ•°: {len(data)}")
    
    # å¤„ç†æ¯ä¸ªæ¨¡å‹
    total_quality_issues = 0
    for cfg in MODEL_CFGS:
        print(f"\n{'='*60}")
        print(f"ğŸ¤– å¼€å§‹å¤„ç†æ¨¡å‹: {cfg['model_name']}")
        print(f"{'='*60}")
        
        processed, skipped, quality_issues = process_questions(data, cfg)
        total_quality_issues += quality_issues
        
        print(f"\nğŸ {cfg['model_name']} å¤„ç†å®Œæˆï¼")
        print(f"   - æ–°å¤„ç†: {processed} é¢˜")
        print(f"   - è·³è¿‡: {skipped} é¢˜")
        print(f"   - è´¨é‡é—®é¢˜: {quality_issues} ä¸ª")
        print(f"   - è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    
    # è´¨é‡é—®é¢˜æ±‡æ€»
    if total_quality_issues > 0:
        print(f"\nâš ï¸ æ€»å…±å‘ç° {total_quality_issues} ä¸ªç­”æ¡ˆè´¨é‡é—®é¢˜")
        print("  å¯åœ¨è¾“å‡ºæ–‡ä»¶ä¸­æŸ¥çœ‹å…·ä½“é—®é¢˜è¯¦æƒ…ï¼ˆquality_issue å­—æ®µï¼‰")
    
    print("\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæ¯•ï¼")